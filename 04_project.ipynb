{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# **DASCore Application: Training**\n",
    "\n",
    "December 1, 2024\n",
    "\n",
    "This notebook shows an example DASCore application: tracking traffic in Salt Lake City. These signals are primarily dominated by the light rail trains. \n",
    "\n",
    "The data were in May of 2023. The original data were down-sampled to 4 Hz. \n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/DASDAE/seg_tutorial/blob/master/04_application.ipynb\">\n",
    "\n",
    "</a>  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "\n",
    "#### Useful links: \n",
    "* [DASCore Tutorial](https://dascore.org/tutorial/concepts.html)\n",
    "* [Numpy Dates and Times](https://numpy.org/devdocs/reference/arrays.datetime.html)\n",
    "* [Pint Units Library](https://pint.readthedocs.io/en/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# First ensure DASCore is installed. If not, install and restart the kernel.\n",
    "try:\n",
    "    import dascore as dc\n",
    "except ImportError:\n",
    "    !pip install dascore\n",
    "    !pip install ipympl\n",
    "    # resetart kernel\n",
    "    import IPython\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel\n",
    "\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, we create a directory of DAS files to simulate the output of an acquisition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory of DAS file\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path(\"UoU_data\")\n",
    "path.mkdir(exist_ok=True)\n",
    "\n",
    "# Get a spool of data with 5 minute patches\n",
    "spool = dc.get_example_spool(\"UoU_lf_urban.hdf5\").chunk(time=60*5)\n",
    "for num, patch in enumerate(spool):\n",
    "    patch_path = (path / f\"UoU_{num}.hdf5\")\n",
    "    if patch_path.exists():\n",
    "        continue\n",
    "    patch.io.write(patch_path, \"dasdae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "We initialize a spool on the directory of DAS files and explore a summary of the contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spool = dc.spool(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spool.get_contents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "There are 10 files, each of 5 minutes of data. One example file looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = spool[2]\n",
    "patch.viz.waterfall(scale=0.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Notice the linear features pre-dominantly moving from left to right. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### **Exercise** (Train Speed)\n",
    "Use the interactive mode of the MPL or a [2D dft](https://dascore.org/api/dascore/transform/fourier/dft.html) to estimate the train velocity. Use [`Patch.slope_filter`](https://dascore.org/api/dascore/proc/filter/slope_filter.html) to make the signal pop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Aggregations\n",
    "\n",
    "Let's calculate some statistics of the data. For example, the standard deviation of each channel (distance) for each of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_max = [\n",
    "    x.abs()\n",
    "    .aggregate(dim=\"time\", method=np.max, dim_reduce=\"first\") \n",
    "    for x in spool\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = (\n",
    "    # Merge all the aggregate patches together\n",
    "    dc.spool(abs_max).chunk(time=None)[0]\n",
    "    # Ensure data type reflects the new meaning\n",
    "    .update_attrs(data_type=\"maximum absolute values\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch.viz.waterfall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### **Exercise** (Aggregations 1)\n",
    "Redo the aggregations above, but calculate the standard deviation for every 60 seconds of data with 10 second overlap. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Moving windows\n",
    "\n",
    "A similar concept to the aggregations is that of a moving window which is implemented with DASCore's [`Patch.rolling`](https://dascore.org/api/dascore/proc/rolling/rolling.html). These are more efficient for overlapping or very dense operations. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "spool_mw = dc.spool(path).chunk(time=120, overlap=20, tolerance=10)\n",
    "\n",
    "output = []\n",
    "for patch in spool_mw:\n",
    "    abs_patch = patch.abs()\n",
    "    sta = abs_patch.rolling(center=True, time=10, step=1).std()\n",
    "    output.append(sta.dropna(\"time\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = (\n",
    "    dc.spool(output)\n",
    "    .chunk(time=None)[0]\n",
    "    .update_attrs(data_type=\"standard deviation\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch.viz.waterfall(scale=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Frequency Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
